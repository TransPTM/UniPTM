{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc06b68f",
   "metadata": {},
   "source": [
    "## Extract PTM from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f39735bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PTM = \"Phosphoserine\"\n",
    "targetAA = 'S'\n",
    "\n",
    "file_path = r'C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\raw_data_processed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "filter_condition = data['Modified residue'].str.contains(PTM, na=False)\n",
    "\n",
    "\n",
    "filtered_data = data[filter_condition]\n",
    "\n",
    "output_path = rf'C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_extracted.csv'\n",
    "filtered_data.to_csv(output_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9e18b14",
   "metadata": {},
   "source": [
    "## Extract PTM positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_extracted.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "pattern_PTM = rf\"MOD_RES (\\d+); /note=\\\"{PTM}.*?\\\"\"\n",
    "\n",
    "\n",
    "def extract_positions(cell):\n",
    "    PTM_numbers = re.findall(pattern_PTM, cell)\n",
    "    PTM_numbers.sort(key=int)\n",
    "    return ', '.join(PTM_numbers) if PTM_numbers else pd.NA\n",
    "\n",
    "\n",
    "\n",
    "df['Position'] = df['Modified residue'].apply(extract_positions)\n",
    "\n",
    "\n",
    "df.dropna(subset=['Position'], inplace=True)\n",
    "\n",
    "new_file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_positions.csv\"\n",
    "\n",
    "df.to_csv(new_file_path, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6391b977",
   "metadata": {},
   "source": [
    "## Check if all positions are extracted from the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_extracted.csv\"\n",
    "file2 = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_positions.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "\n",
    "entries_file1 = set(df1['Entry'])\n",
    "entries_file2 = set(df2['Entry'])\n",
    "\n",
    "unique_entries = entries_file1 - entries_file2\n",
    "\n",
    "print(\"Entries that are present in the first file but not in the second file:\")\n",
    "for entry in unique_entries:\n",
    "    print(entry)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65df0d8d",
   "metadata": {},
   "source": [
    "## Add labels, masks, possition numbers, and tragart amino acid numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d1b1f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\PTM2_data\\{PTM}_with_positions.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def create_label_and_mask(df):\n",
    "    labels = []\n",
    "    masks = []\n",
    "    pos_nums = []  \n",
    "    targetAA_nums = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        length = row['Length']\n",
    "        sequence = row['Sequence']\n",
    "        \n",
    "        
    "        label = np.zeros(length, dtype=int)\n",
    "        \n",
    "        # 如果Position列不为空，则将对应位置设为1\n",
    "        if pd.notnull(row['Position']):\n",
    "            positions = [int(pos) - 1 for pos in str(row['Position']).split(', ')]  \n",
    "            label[positions] = 1\n",
    "        \n",
    "        labels.append(label)\n",
    "        pos_nums.append(np.sum(label))\n",
    "        \n",
    "\n",
    "        mask = np.array([1 if amino_acid == targetAA else 0 for amino_acid in sequence], dtype=int)\n",
    "        masks.append(mask)\n",
    "        targetAA_nums.append(np.sum(mask))\n",
    "    \n",
    "   \n",
    "    df['Label'] = [','.join(map(str, label)) for label in labels]\n",
    "    df['Mask'] = [','.join(map(str, mask)) for mask in masks]\n",
    "    df['Pos_num'] = pos_nums\n",
    "    df['TargetAA_num'] = targetAA_nums\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = create_label_and_mask(df)\n",
    "\n",
    "\n",
    "output_file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\PTM2_data\\{PTM}_with_labels.csv\"  \n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b610cb2a",
   "metadata": {},
   "source": [
    "## Check if labels and mask consistent with positions and targetAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_labels.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "def verify_positions_and_count(sequence, positions, target_count):\n",
    "\n",
    "    pos_list = [int(pos) for pos in str(positions).split(',') if pos.strip().isdigit()]\n",
    "\n",
    "    positions_correct = all(sequence[pos - 1].upper() == targetAA for pos in pos_list)\n",
    "    \n",
    "\n",
    "    targetAA_count = sequence.upper().count(targetAA)\n",
    "\n",
    "    count_correct = (targetAA_count == target_count)\n",
    "    \n",
    "    return positions_correct, count_correct, targetAA_count\n",
    "\n",
    "df[['Positions_Correct', 'Count_Correct', 'Actual_targetAA_Count']] = df.apply(\n",
    "    lambda row: verify_positions_and_count(row['Sequence'], row['Position'], row['TargetAA_num']), \n",
    "    axis=1, result_type='expand'\n",
    ")\n",
    "\n",
    "incorrect_rows = df[~(df['Positions_Correct'] & df['Count_Correct'])]\n",
    "\n",
    "if not incorrect_rows.empty:\n",
    "    print(\"Rows that do not meet the criteria:\")\n",
    "    print(incorrect_rows)\n",
    "else:\n",
    "    print(\"All rows meet the criteria.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84f49ba0",
   "metadata": {},
   "source": [
    "## csv to fasta for CD-HIT preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "db92135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def csv_to_fasta_with_mapping(df, fasta_file_path, mapping_file_path):\n",
    "    with open(fasta_file_path, 'w') as fasta_file, open(mapping_file_path, 'w') as mapping_file:\n",
    "        \n",
    "        mapping_file.write(\"Entry,Modified residue,Position,Label,Mask,Pos_num,TargetAA_num\\n\")\n",
    "        for _, row in df.iterrows():\n",
    "           \n",
    "            description = f\">{row['Entry']}\"\n",
    "            sequence = row['Sequence']\n",
    "            \n",
    "            fasta_file.write(f\"{description}\\n{sequence}\\n\\n\")\n",
    "          \n",
    "            mapping_info = f\"{row['Entry']},{row['Modified residue']},{row['Position']},{row['Label']},{row['Mask']},{row['Pos_num']},{row['TargetAA_num']}\\n\"\n",
    "            mapping_file.write(mapping_info)\n",
    "\n",
    "\n",
    "fasta_file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_labels.fasta\"  \n",
    "mapping_file_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_mapping.csv\"  \n",
    "\n",
    "\n",
    "df = pd.read_csv(rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_labels.csv\"  )\n",
    "\n",
    "\n",
    "csv_to_fasta_with_mapping(df, fasta_file_path, mapping_file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c0a3c16",
   "metadata": {},
   "source": [
    "## fasta to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7f4628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of Pos_num: 14347\n",
      "Total sum of TargetAA_num: 168907\n",
      "Total number of rows (excluding header): 3970\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "original_csv_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_labels.csv\"\n",
    "df = pd.read_csv(original_csv_path)\n",
    "\n",
    "clustered_fasta_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_with_labels_clustered.fasta\"\n",
    "clustered_ids = [record.id for record in SeqIO.parse(clustered_fasta_path, 'fasta')]\n",
    "\n",
    "\n",
    "filtered_df = df[df['Entry'].isin(clustered_ids)]\n",
    "\n",
    "\n",
    "pos_num_sum = filtered_df['Pos_num'].sum()\n",
    "target_aa_num_sum = filtered_df['TargetAA_num'].sum()\n",
    "\n",
    "\n",
    "total_rows = filtered_df.shape[0]\n",
    "\n",
    "\n",
    "print(f\"Total sum of Pos_num: {pos_num_sum}\")\n",
    "print(f\"Total sum of TargetAA_num: {target_aa_num_sum}\")\n",
    "print(f\"Total number of rows (excluding header): {total_rows}\")\n",
    "\n",
    "\n",
    "filtered_csv_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_clustered.csv\"\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8995359b",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b87ab17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Statistics:\n",
      "Total sum of Pos_num: 11436\n",
      "Total sum of TargetAA_num: 135563\n",
      "Total number of rows: 3176\n",
      "\n",
      "Test Set Statistics:\n",
      "Total sum of Pos_num: 2911\n",
      "Total sum of TargetAA_num: 33344\n",
      "Total number of rows: 794\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "data_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_clustered.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "data['Pos_num_grouped'] = data['Pos_num'].apply(lambda x: '>5' if x > 5 else str(x))\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(np.zeros(data.shape[0]), data['Pos_num_grouped']):\n",
    "    data['Set'] = 'train'  \n",
    "    data.loc[test_index, 'Set'] = 'test'  \n",
    "\n",
    "\n",
    "test_ratio = data['Set'].value_counts(normalize=True)['test']\n",
    "\n",
    "\n",
    "desired_test_ratio = 0.2\n",
    "if test_ratio > desired_test_ratio:\n",
    "   \n",
    "    excess_test_samples = int((test_ratio - desired_test_ratio) * data.shape[0])\n",
    "    test_indices = data[data['Set'] == 'test'].index\n",
    "    move_to_train = np.random.choice(test_indices, size=excess_test_samples, replace=False)\n",
    "    data.loc[move_to_train, 'Set'] = 'train'\n",
    "elif test_ratio < desired_test_ratio:\n",
    "   \n",
    "    excess_train_samples = int((desired_test_ratio - test_ratio) * data.shape[0])\n",
    "    train_indices = data[data['Set'] == 'train'].index\n",
    "    move_to_test = np.random.choice(train_indices, size=excess_train_samples, replace=False)\n",
    "    data.loc[move_to_test, 'Set'] = 'test'\n",
    "\n",
    "\n",
    "data.drop('Pos_num_grouped', axis=1, inplace=True)\n",
    "\n",
    "data = data.sort_values(by='Set', ascending=False)\n",
    "\n",
    "\n",
    "output_path = rf\"C:\\Users\\mengl\\OneDrive - City University of Hong Kong - Student\\Desktop\\uniptm_data\\{PTM}_clustered_splited.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n",
    "\n",
    "\n",
    "train_data = data[data['Set'] == 'train']\n",
    "test_data = data[data['Set'] == 'test']\n",
    "\n",
    "\n",
    "train_pos_num_sum = train_data['Pos_num'].sum()\n",
    "train_target_aa_num_sum = train_data['TargetAA_num'].sum()\n",
    "train_total_rows = train_data.shape[0]\n",
    "\n",
    "\n",
    "print(\"Training Set Statistics:\")\n",
    "print(f\"Total sum of Pos_num: {train_pos_num_sum}\")\n",
    "print(f\"Total sum of TargetAA_num: {train_target_aa_num_sum}\")\n",
    "print(f\"Total number of rows: {train_total_rows}\")\n",
    "\n",
    "\n",
    "test_pos_num_sum = test_data['Pos_num'].sum()\n",
    "test_target_aa_num_sum = test_data['TargetAA_num'].sum()\n",
    "test_total_rows = test_data.shape[0]\n",
    "\n",
    "\n",
    "print(\"\\nTest Set Statistics:\")\n",
    "print(f\"Total sum of Pos_num: {test_pos_num_sum}\")\n",
    "print(f\"Total sum of TargetAA_num: {test_target_aa_num_sum}\")\n",
    "print(f\"Total number of rows: {test_total_rows}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0cbb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
